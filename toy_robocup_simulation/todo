

- (done) write state-producing and reward producing function for the RobocupEnv class
- write training loop with a neural network that produces actions
    - write code to sample from distribution implied by Q-values
    - test code to make sure it's doing something reasonable
    - set last layer biases to be higher in order to start optimistically, to explore more in beginning.
- visualization of reward over time
- implement device setting in the environment so we can simulate on GPU

- implementing QLearner
- writing more comments to explain what's going on
- write libraries to save game states

- after implementing a TD(0) Q-Learner, write the general TD(n) case
- implement importance sampling to learn off-policy from old games
-

